# -*- coding: utf-8 -*-
"""ADOBE_testing_pdfs.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Wq2lI8NyLWPgtK6lc2nH4wpwjJu4yX1_
"""

# ENHANCED PDF EXTRACTION - IMPROVED ORIGINAL APPROACH
# This code improves upon the original approach with better error handling and features

# Cell 1: Install Dependencies
!pip install reportlab pillow pdfplumber pymupdf pandas numpy matplotlib seaborn

# Cell 2: Import Libraries and Setup
import os
import glob
import json
import pdfplumber
import fitz  # PyMuPDF
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from reportlab.pdfgen import canvas
from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer
from reportlab.lib.pagesizes import letter, A4
from reportlab.lib import colors
from reportlab.lib.styles import getSampleStyleSheet
from PIL import Image as PILImage, ImageDraw, ImageFont
import warnings
warnings.filterwarnings('ignore')

# Cell 3: Enhanced Test PDF Generation
def create_enhanced_test_pdfs():
    """Generate diverse test PDFs with various complexities"""

    output_dir = "enhanced_test_pdfs"
    os.makedirs(output_dir, exist_ok=True)

    # 1. Multi-column academic paper
    multi_col_path = os.path.join(output_dir, "multi_column_paper.pdf")
    c = canvas.Canvas(multi_col_path, pagesize=A4)
    width, height = A4

    # Title
    c.setFont("Helvetica-Bold", 16)
    c.drawString(50, height-50, "Enhanced PDF Structure Analysis: A Comprehensive Study")

    # Authors
    c.setFont("Helvetica-Oblique", 12)
    c.drawString(50, height-70, "Authors: Dr. Jane Smith¹, Prof. John Doe²")

    # Abstract
    c.setFont("Helvetica-Bold", 14)
    c.drawString(50, height-110, "Abstract")
    c.setFont("Helvetica", 10)
    abstract_text = [
        "This paper presents a novel approach to PDF structure extraction using hybrid",
        "methodologies combining rule-based and machine learning techniques.",
        "Our results show 95% accuracy improvement over traditional methods."
    ]
    y_pos = height - 130
    for line in abstract_text:
        c.drawString(50, y_pos, line)
        y_pos -= 15

    # Two column content
    col1_x, col2_x = 50, 300
    col_width = 200

    # Section 1
    c.setFont("Helvetica-Bold", 12)
    c.drawString(col1_x, height-220, "1. Introduction")
    c.setFont("Helvetica", 9)
    intro_lines = [
        "PDF documents represent one of the most",
        "challenging formats for automated content",
        "extraction. Traditional approaches often",
        "fail when dealing with complex layouts,",
        "multi-column structures, and mixed content",
        "types including tables and figures."
    ]
    y_pos = height - 240
    for line in intro_lines:
        c.drawString(col1_x, y_pos, line)
        y_pos -= 12

    # Section 2 in second column
    c.setFont("Helvetica-Bold", 12)
    c.drawString(col2_x, height-220, "2. Methodology")
    c.setFont("Helvetica", 9)
    method_lines = [
        "Our approach combines multiple extraction",
        "libraries including pdfplumber and PyMuPDF",
        "to create a robust hybrid system that can",
        "handle various document structures and",
        "formatting complexities with high accuracy",
        "and performance optimization."
    ]
    y_pos = height - 240
    for line in method_lines:
        c.drawString(col2_x, y_pos, line)
        y_pos -= 12

    # Footnotes
    c.setFont("Helvetica", 8)
    c.drawString(50, 80, "¹ University of Technology, Department of Computer Science")
    c.drawString(50, 70, "² Research Institute for Advanced Computing")

    c.save()

    # 2. Complex table document
    table_path = os.path.join(output_dir, "complex_tables.pdf")
    doc = SimpleDocTemplate(table_path, pagesize=letter)
    styles = getSampleStyleSheet()

    elements = []
    elements.append(Paragraph("Financial Report Q4 2024", styles['Title']))
    elements.append(Spacer(1, 20))

    # Complex table with merged cells effect
    financial_data = [
        ["Category", "Q1", "Q2", "Q3", "Q4", "Total"],
        ["Revenue", "$125K", "$145K", "$165K", "$185K", "$620K"],
        ["Expenses", "$95K", "$105K", "$125K", "$135K", "$460K"],
        ["Marketing", "$25K", "$30K", "$35K", "$40K", "$130K"],
        ["Operations", "$45K", "$50K", "$55K", "$60K", "$210K"],
        ["Other", "$25K", "$25K", "$35K", "$35K", "$120K"],
        ["Net Profit", "$30K", "$40K", "$40K", "$50K", "$160K"]
    ]

    table = Table(financial_data, colWidths=[80, 60, 60, 60, 60, 80])
    table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.darkblue),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
        ('FONTSIZE', (0, 0), (-1, 0), 12),
        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
        ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
        ('GRID', (0, 0), (-1, -1), 1, colors.black),
        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
    ]))

    elements.append(table)
    elements.append(Spacer(1, 30))

    # Second table - employee data
    elements.append(Paragraph("Employee Performance Metrics", styles['Heading2']))
    elements.append(Spacer(1, 12))

    employee_data = [
        ["Employee ID", "Name", "Department", "Performance Score", "Bonus Eligible"],
        ["EMP001", "Alice Johnson", "Engineering", "4.8/5.0", "Yes"],
        ["EMP002", "Bob Smith", "Marketing", "4.2/5.0", "Yes"],
        ["EMP003", "Carol Davis", "Finance", "4.9/5.0", "Yes"],
        ["EMP004", "David Wilson", "Operations", "3.8/5.0", "No"],
    ]

    emp_table = Table(employee_data, colWidths=[70, 100, 80, 100, 80])
    emp_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.green),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
        ('FONTSIZE', (0, 0), (-1, 0), 10),
        ('GRID', (0, 0), (-1, -1), 1, colors.black),
        ('ALTERNATEROWCOLOR', (0, 1), (-1, -1), [colors.white, colors.lightgrey]),
    ]))

    elements.append(emp_table)
    doc.build(elements)

    # 3. Mixed content with images and text
    mixed_path = os.path.join(output_dir, "mixed_content.pdf")
    c = canvas.Canvas(mixed_path, pagesize=letter)
    width, height = letter

    # Create a sample image
    img_path = os.path.join(output_dir, "sample_chart.png")
    img = PILImage.new("RGB", (300, 200), color="white")
    draw = ImageDraw.Draw(img)

    # Draw a simple bar chart
    draw.rectangle([50, 50, 100, 150], fill="blue")
    draw.rectangle([120, 80, 170, 150], fill="red")
    draw.rectangle([190, 30, 240, 150], fill="green")
    draw.text((50, 160), "Q1", fill="black")
    draw.text((120, 160), "Q2", fill="black")
    draw.text((190, 160), "Q3", fill="black")
    draw.text((10, 10), "Revenue Trends", fill="black")
    img.save(img_path)

    # Add content to PDF
    c.setFont("Helvetica-Bold", 18)
    c.drawString(50, height-50, "Quarterly Business Review")

    c.setFont("Helvetica", 12)
    c.drawString(50, height-100, "Executive Summary:")
    c.drawString(50, height-120, "This document provides a comprehensive overview of our Q3 performance")
    c.drawString(50, height-140, "including financial metrics, operational highlights, and strategic initiatives.")

    # Insert image
    c.drawImage(img_path, 50, height-400, width=300, height=200)

    # Continue with text below image
    c.drawString(50, height-450, "Key Performance Indicators:")
    c.drawString(70, height-470, "• Revenue Growth: 15% YoY")
    c.drawString(70, height-490, "• Customer Satisfaction: 94%")
    c.drawString(70, height-510, "• Market Share: 23%")
    c.drawString(70, height-530, "• Employee Retention: 89%")

    c.save()

    # 4. Structured document with numbering
    structured_path = os.path.join(output_dir, "structured_document.pdf")
    c = canvas.Canvas(structured_path, pagesize=letter)
    width, height = letter

    c.setFont("Helvetica-Bold", 20)
    c.drawString(50, height-50, "Software Requirements Specification")

    y_pos = height - 100
    sections = [
        ("1.", "Introduction", [
            "1.1 Purpose",
            "1.2 Scope",
            "1.3 Definitions and Acronyms"
        ]),
        ("2.", "System Overview", [
            "2.1 System Architecture",
            "2.2 System Interfaces",
            "2.3 User Classes and Characteristics"
        ]),
        ("3.", "Functional Requirements", [
            "3.1 User Authentication",
            "3.2 Data Management",
            "3.3 Reporting System"
        ])
    ]

    for section_num, section_title, subsections in sections:
        c.setFont("Helvetica-Bold", 14)
        c.drawString(50, y_pos, f"{section_num} {section_title}")
        y_pos -= 25

        c.setFont("Helvetica", 11)
        for subsection in subsections:
            c.drawString(70, y_pos, subsection)
            y_pos -= 18
        y_pos -= 10

    c.save()

    print(f"Generated 4 enhanced test PDFs in '{output_dir}' directory:")
    for filename in os.listdir(output_dir):
        if filename.endswith('.pdf'):
            print(f"- {filename}")

    return output_dir

# Cell 4: Create Test PDFs
test_dir = create_enhanced_test_pdfs()

# Cell 5: Enhanced PDF Extraction Functions
def extract_comprehensive_metadata(pdf_path):
    """Extract comprehensive metadata from PDF"""

    metadata = {
        'file_path': pdf_path,
        'file_name': os.path.basename(pdf_path),
        'characters': [],
        'blocks': [],
        'lines': [],
        'tables': [],
        'images': [],
        'page_info': [],
        'font_analysis': {},
        'structure_analysis': {}
    }

    try:
        # Character-level extraction with pdfplumber
        with pdfplumber.open(pdf_path) as pdf:
            total_chars = 0
            all_fonts = []
            all_sizes = []

            for page_num, page in enumerate(pdf.pages, 1):
                # Page dimensions
                page_info = {
                    'page': page_num,
                    'width': page.width,
                    'height': page.height,
                    'rotation': getattr(page, 'rotation', 0)
                }
                metadata['page_info'].append(page_info)

                # Character extraction
                for char in page.chars:
                    char_data = {
                        'page': page_num,
                        'text': char.get('text', ''),
                        'fontname': char.get('fontname', ''),
                        'size': char.get('size', 0),
                        'x0': char.get('x0', 0),
                        'x1': char.get('x1', 0),
                        'top': char.get('top', 0),
                        'bottom': char.get('bottom', 0),
                        'width': char.get('width', 0),
                        'height': char.get('height', 0)
                    }
                    metadata['characters'].append(char_data)
                    total_chars += 1

                    if char_data['fontname']:
                        all_fonts.append(char_data['fontname'])
                    if char_data['size']:
                        all_sizes.append(char_data['size'])

                # Table extraction
                tables = page.find_tables()
                for table_idx, table in enumerate(tables):
                    try:
                        table_data = {
                            'page': page_num,
                            'table_id': f"table_{page_num}_{table_idx}",
                            'bbox': table.bbox,
                            'rows': len(table.rows) if table.rows else 0,
                            'cols': len(table.rows[0]) if table.rows and table.rows[0] else 0,
                            'data': table.extract() if table.rows else []
                        }
                        metadata['tables'].append(table_data)
                    except Exception as e:
                        print(f"Error extracting table {table_idx} on page {page_num}: {e}")

                # Image extraction
                try:
                    for img_idx, img in enumerate(page.images):
                        img_data = {
                            'page': page_num,
                            'image_id': f"img_{page_num}_{img_idx}",
                            'bbox': [img.get('x0', 0), img.get('top', 0),
                                   img.get('x1', 0), img.get('bottom', 0)],
                            'width': img.get('width', 0),
                            'height': img.get('height', 0)
                        }
                        metadata['images'].append(img_data)
                except Exception as e:
                    print(f"Error extracting images on page {page_num}: {e}")

        # Block-level extraction with PyMuPDF
        doc = fitz.open(pdf_path)
        for page_idx in range(len(doc)):
            page = doc[page_idx]
            page_dict = page.get_text("dict")

            for block_idx, block in enumerate(page_dict.get("blocks", [])):
                if "lines" not in block:
                    continue

                bbox = block.get("bbox", [0, 0, 0, 0])

                for line_idx, line in enumerate(block["lines"]):
                    for span_idx, span in enumerate(line.get("spans", [])):
                        block_data = {
                            'page': page_idx + 1,
                            'block_id': f"block_{page_idx}_{block_idx}_{line_idx}_{span_idx}",
                            'text': span.get('text', ''),
                            'font': span.get('font', ''),
                            'size': span.get('size', 0),
                            'flags': span.get('flags', 0),
                            'bbox': span.get('bbox', [0, 0, 0, 0]),
                            'block_bbox': bbox
                        }
                        metadata['blocks'].append(block_data)

        doc.close()

        # Font analysis
        if all_fonts:
            font_counts = pd.Series(all_fonts).value_counts()
            metadata['font_analysis'] = {
                'total_fonts': len(font_counts),
                'most_common_font': font_counts.index[0] if len(font_counts) > 0 else None,
                'font_diversity': font_counts.to_dict(),
                'size_stats': {
                    'min_size': min(all_sizes) if all_sizes else 0,
                    'max_size': max(all_sizes) if all_sizes else 0,
                    'mean_size': np.mean(all_sizes) if all_sizes else 0,
                    'size_variety': len(set(all_sizes)) if all_sizes else 0
                }
            }

        # Line reconstruction
        if metadata['characters']:
            df_chars = pd.DataFrame(metadata['characters'])
            df_chars['line_top'] = df_chars['top'].round().astype(int)

            lines_df = (
                df_chars
                .sort_values(['page', 'line_top', 'x0'])
                .groupby(['page', 'line_top'])
                .agg({
                    'text': ''.join,
                    'x0': 'min',
                    'x1': 'max',
                    'top': 'min',
                    'bottom': 'max',
                    'size': 'mean',
                    'fontname': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else ''
                })
                .reset_index()
            )

            metadata['lines'] = lines_df.to_dict('records')

        # Structure analysis
        if metadata['lines']:
            lines_df = pd.DataFrame(metadata['lines'])

            # Detect potential headers (larger font sizes)
            if 'size' in lines_df.columns:
                size_mean = lines_df['size'].mean()
                size_std = lines_df['size'].std()
                header_threshold = size_mean + size_std

                potential_headers = lines_df[lines_df['size'] > header_threshold]

                metadata['structure_analysis'] = {
                    'total_lines': len(lines_df),
                    'potential_headers': len(potential_headers),
                    'avg_line_length': lines_df['text'].str.len().mean() if 'text' in lines_df.columns else 0,
                    'header_candidates': potential_headers[['page', 'text', 'size']].to_dict('records') if len(potential_headers) > 0 else []
                }

    except Exception as e:
        print(f"Error processing {pdf_path}: {e}")
        metadata['error'] = str(e)

    return metadata

# Cell 6: Process All Test PDFs
def process_pdf_directory(directory_path):
    """Process all PDFs in directory and return comprehensive results"""

    pdf_files = glob.glob(os.path.join(directory_path, "*.pdf"))
    results = {}

    print(f"Found {len(pdf_files)} PDF files to process...")

    for pdf_path in pdf_files:
        print(f"\nProcessing: {os.path.basename(pdf_path)}")

        metadata = extract_comprehensive_metadata(pdf_path)
        base_name = os.path.splitext(os.path.basename(pdf_path))[0]

        # Save individual results
        results[base_name] = metadata

        # Save to CSV files
        if metadata['characters']:
            pd.DataFrame(metadata['characters']).to_csv(f"{base_name}_characters.csv", index=False)
            print(f"  ✓ Saved {len(metadata['characters'])} characters")

        if metadata['blocks']:
            pd.DataFrame(metadata['blocks']).to_csv(f"{base_name}_blocks.csv", index=False)
            print(f"  ✓ Saved {len(metadata['blocks'])} blocks")

        if metadata['lines']:
            pd.DataFrame(metadata['lines']).to_csv(f"{base_name}_lines.csv", index=False)
            print(f"  ✓ Saved {len(metadata['lines'])} lines")

        if metadata['tables']:
            pd.DataFrame(metadata['tables']).to_csv(f"{base_name}_tables.csv", index=False)
            print(f"  ✓ Saved {len(metadata['tables'])} tables")

        if metadata['images']:
            pd.DataFrame(metadata['images']).to_csv(f"{base_name}_images.csv", index=False)
            print(f"  ✓ Saved {len(metadata['images'])} images")

    # Save combined results
    with open('combined_extraction_results.json', 'w') as f:
        json.dump(results, f, indent=2, default=str)

    return results

# Cell 7: Run Processing
results = process_pdf_directory(test_dir)

# Cell 8: Analysis and Visualization
def analyze_extraction_results(results):
    """Analyze extraction results and create visualizations"""

    # Prepare data for analysis
    analysis_data = []

    for pdf_name, metadata in results.items():
        if 'error' not in metadata:
            analysis_data.append({
                'pdf_name': pdf_name,
                'total_characters': len(metadata.get('characters', [])),
                'total_blocks': len(metadata.get('blocks', [])),
                'total_lines': len(metadata.get('lines', [])),
                'total_tables': len(metadata.get('tables', [])),
                'total_images': len(metadata.get('images', [])),
                'total_pages': len(metadata.get('page_info', [])),
                'font_diversity': metadata.get('font_analysis', {}).get('total_fonts', 0),
                'size_variety': metadata.get('font_analysis', {}).get('size_stats', {}).get('size_variety', 0)
            })

    if not analysis_data:
        print("No valid data to analyze")
        return

    df_analysis = pd.DataFrame(analysis_data)

    # Create visualizations
    plt.figure(figsize=(15, 10))

    # Characters per PDF
    plt.subplot(2, 3, 1)
    plt.bar(df_analysis['pdf_name'], df_analysis['total_characters'])
    plt.title('Characters Extracted per PDF')
    plt.xticks(rotation=45)
    plt.ylabel('Character Count')

    # Lines distribution
    plt.subplot(2, 3, 2)
    plt.bar(df_analysis['pdf_name'], df_analysis['total_lines'])
    plt.title('Lines Extracted per PDF')
    plt.xticks(rotation=45)
    plt.ylabel('Line Count')

    # Font diversity
    plt.subplot(2, 3, 3)
    plt.bar(df_analysis['pdf_name'], df_analysis['font_diversity'])
    plt.title('Font Diversity per PDF')
    plt.xticks(rotation=45)
    plt.ylabel('Unique Fonts')

    # Tables and images
    plt.subplot(2, 3, 4)
    x = range(len(df_analysis))
    width = 0.35
    plt.bar([i - width/2 for i in x], df_analysis['total_tables'], width, label='Tables')
    plt.bar([i + width/2 for i in x], df_analysis['total_images'], width, label='Images')
    plt.title('Tables and Images per PDF')
    plt.xticks(x, df_analysis['pdf_name'], rotation=45)
    plt.ylabel('Count')
    plt.legend()

    # Size variety
    plt.subplot(2, 3, 5)
    plt.bar(df_analysis['pdf_name'], df_analysis['size_variety'])
    plt.title('Font Size Variety per PDF')
    plt.xticks(rotation=45)
    plt.ylabel('Unique Sizes')

    # Summary statistics
    plt.subplot(2, 3, 6)
    summary_stats = df_analysis[['total_characters', 'total_blocks', 'total_lines']].sum()
    plt.pie(summary_stats.values, labels=summary_stats.index, autopct='%1.1f%%')
    plt.title('Overall Content Distribution')

    plt.tight_layout()
    plt.savefig('extraction_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()

    # Print summary statistics
    print("\n=== EXTRACTION SUMMARY ===")
    print(f"Total PDFs processed: {len(df_analysis)}")
    print(f"Total characters extracted: {df_analysis['total_characters'].sum():,}")
    print(f"Total lines reconstructed: {df_analysis['total_lines'].sum():,}")
    print(f"Total tables found: {df_analysis['total_tables'].sum()}")
    print(f"Total images found: {df_analysis['total_images'].sum()}")
    print(f"Average font diversity: {df_analysis['font_diversity'].mean():.1f}")

    return df_analysis

# Cell 9: Run Analysis
analysis_results = analyze_extraction_results(results)

# Cell 10: Export and Download Functions
def export_results_for_download():
    """Prepare all results for easy download"""

    # Create a summary report
    summary_report = []
    summary_report.append("# PDF EXTRACTION RESULTS SUMMARY\n")
    summary_report.append(f"Generated on: {pd.Timestamp.now()}\n")
    summary_report.append(f"Total files processed: {len(results)}\n\n")

    for pdf_name, metadata in results.items():
        if 'error' not in metadata:
            summary_report.append(f"## {pdf_name}\n")
            summary_report.append(f"- Characters: {len(metadata.get('characters', []))}\n")
            summary_report.append(f"- Lines: {len(metadata.get('lines', []))}\n")
            summary_report.append(f"- Tables: {len(metadata.get('tables', []))}\n")
            summary_report.append(f"- Images: {len(metadata.get('images', []))}\n")
            summary_report.append(f"- Pages: {len(metadata.get('page_info', []))}\n")

            font_analysis = metadata.get('font_analysis', {})
            if font_analysis:
                summary_report.append(f"- Fonts used: {font_analysis.get('total_fonts', 0)}\n")
                summary_report.append(f"- Size range: {font_analysis.get('size_stats', {}).get('min_size', 0):.1f} - {font_analysis.get('size_stats', {}).get('max_size', 0):.1f}\n")
            summary_report.append("\n")

    with open('extraction_summary_report.md', 'w') as f:
        f.writelines(summary_report)

    print("✅ All files ready for download:")
    print("- Individual CSV files for each PDF")
    print("- combined_extraction_results.json")
    print("- extraction_summary_report.md")
    print("- extraction_analysis.png")

    # List all generated files
    csv_files = glob.glob("*.csv")
    json_files = glob.glob("*.json")
    other_files = ['extraction_summary_report.md', 'extraction_analysis.png']

    all_files = csv_files + json_files + other_files
    print(f"\nTotal files generated: {len(all_files)}")

    return all_files

# Cell 11: Final Export
generated_files = export_results_for_download()

print("\n" + "="*50)
print("ENHANCED PDF EXTRACTION COMPLETE!")
print("="*50)
print("The system has successfully:")
print("✓ Generated 4 diverse test PDFs")
print("✓ Extracted character-level metadata")
print("✓ Processed block-level structures")
print("✓ Reconstructed line-level text")
print("✓ Detected tables and images")
print("✓ Analyzed font diversity and document structure")
print("✓ Created visualizations and summary reports")
print("✓ Saved all results in multiple formats")
print("\nAll data is now ready for machine learning pipeline!")

import pandas as pd
import glob

# Get a list of all generated CSV files
csv_files = glob.glob("*.csv")

print("Displaying column names of generated CSV files:")
print("-" * 50)

for csv_file in csv_files:
    try:
        print(f"\nColumns for: {csv_file}")
        df = pd.read_csv(csv_file)
        print(df.columns.tolist())
        print("-" * 50)
    except Exception as e:
        print(f"Error reading {csv_file}: {e}")

import json

try:
    with open('combined_extraction_results.json', 'r') as f:
        combined_results = json.load(f)
    print(json.dumps(combined_results, indent=2))
except FileNotFoundError:
    print("Error: 'combined_extraction_results.json' not found.")
except json.JSONDecodeError:
    print("Error: Could not decode JSON from 'combined_extraction_results.json'.")
except Exception as e:
    print(f"An unexpected error occurred: {e}")